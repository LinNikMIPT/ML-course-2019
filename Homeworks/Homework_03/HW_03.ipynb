{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3\n",
    "\n",
    "Запускайте этот ноутбук в google colab! Файлы с разрешением .ipynb можно открывать на гугл диске с помощью Google Colaboratory. Не забудьте подключить GPU! Видео, где рассказано о основе работы с Google Colab: [YouTube](https://www.youtube.com/watch?v=HWN_DVRB1G4&feature=youtu.be) (есть возможность включить английские субтитры).\n",
    "\n",
    "Run this note using google colab! You can open .ipynb files on google drive using Google Colaboratory. Don't forget to turn GPU on. There's a video tutorial for Google Colab: [YouTube](https://www.youtube.com/watch?v=HWN_DVRB1G4&feature=youtu.be) (уnglish subtitles are available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задча №1\n",
    "\n",
    "Сравним качество распознавания изображений, время обучения, время работы и количество параметров у нескольких нейронных сетей.\n",
    "Прежде всего обучим сверточную нейросеть, которую мы построили на семинаре. В качестве данных будем использовать известный набор [CIFAR10](http://www.cs.toronto.edu/~kriz/cifar.html), в котором 60000 изображений 10 классов размера 32x32 (по 6 тысяч изображений на каждый класс) - 10000 в тестовом наборе и 50000 в тренировочном.\n",
    "\n",
    "Compare image recognition quality, learning time, runtime and number of parameters for several neural networks. First of all train convolutional neural network we built in class. Use [CIFAR10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset, which contains 60000 images of 10 classes, size 32x32. 10000images for test and 50000 for train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "from  keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, MaxPool2D\n",
    "from keras.layers import Conv2D, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels = 3\n",
    "classes = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "batch_size = ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "nb_epoch = ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using load_data()\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = X_train.shape[0]\n",
    "num_test = X_test.shape[0]\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image example\n",
    "\n",
    "n = 1\n",
    "plt.imshow(X_train[n])\n",
    "plt.show()\n",
    "print(\"Class number:\", y_train[n])\n",
    "print(\"Object type:\", classes[y_train[n][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормируем входы, чтобы значения якости всех пикселей были в диапазоне 0-1\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем метки класса в формат onehotencoder\n",
    "\n",
    "print(y_train[n])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(Y_train[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализуйте и обучите такую же сверточную нейронную сеть, которая была нa семинаре (copy-paste), не забыв изменить параметры входного изображения:**\n",
    "\n",
    "**Make and train a neural network exactly like we did in class (copy-paste). Don't forget to change parameters of input tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на модель\n",
    "# Have a look at our model (use .summary())\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомпилируйте и обучите сеть с использованием генераторов и callbacks_list (сохранять модель не нужно, то есть можно обойтись без ModelCheckpoint), замерьте время обучения сети.\n",
    "\n",
    "Compile and train network using generators and callbacks_list (you don't have to save the model, so it's not nesseccary to use ModelCheckpoint). Measure the learning time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отрисуйте графики точности и потерь на тестовом и на тренировочном множестве для сверточной неронной сети (в classifier_history хранится все необходимая для этого информация - см. HW_02):**\n",
    "\n",
    "**Vusialize the accuracy and the loss on test and train samples for convoltional network (all information is in classifier_history, as in HW_02):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посчитайте и постройте гистограммы precision и recall для каждого класса:**\n",
    "\n",
    "**Make precision and recall histograms for each class:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задча №2\n",
    "\n",
    "Используя наиболее понравившийся вам фреймворк глубокого обучения, реализуйте и обучите две полносвязные нейронные сети с архитектурой 1000 -> 800 -> 600 -> 400 -> 200 -> 10 (количество нейронов в слоях от входного до выходного). В качестве функции активации для последнего слоя используйте Softmax. Для одной из них используйте dropout и батч регуляризацию, а для другой - нет. Задайте большое количество эпох обучения, сравните поведения функций потерь и метрик качества для этих сетей (их надо нарисовать!). Сделайте выводы. \n",
    "\n",
    "Using your favourite deep learning framework, build and train two fully connected neural networks with folowing architecture: 1000 -> 800 -> 600 -> 400 -> 200 -> 10 (the number of neurons from input to output layer). Use Softmax as activation function for the output layer. Use dropout and batch regularisation for one of networks, and don't use them for another. Set 20-40 as number of epochs and compare loss and quality metrics dymanics for both networks (you also have to visualise them!). Make some conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как у нас цветные изображения, а мы собираемся использовать полносвязные сети, то нам придется каким-либо образом преобразовать трехмерные тензоры в векторы. Сделаем мы это так: вытянем все три канала в один вектор.\n",
    "\n",
    "We using fully connected networks, but we have color images, they should be tranformed from 3-dimesional tensors to vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_one_channel = X_train.reshape(X_train.shape[0], img_rows * img_cols * img_channels)\n",
    "X_test_one_channel = X_test.reshape(X_test.shape[0], img_rows * img_cols * img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\", X_train_one_channel.shape)\n",
    "print(\"Test:\", X_test_one_channel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте сеть с архитектурой 1000 -> 800 -> 600 -> 400 -> 200 -> 10 и обучите ее (уже без использования генераторов), заметрьте время обучения\n",
    "\n",
    "Build and train network with architecture: 1000 -> 800 -> 600 -> 400 -> 200 -> 10 (without using generators), measure learning time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на модель\n",
    "# Have a look at our model (use .summary())\n",
    "\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисуйте графики точности и потерь на тестовом и на тренировочном множестве для сверточной неронной сети\n",
    "\n",
    "Vusialize the accuracy and the loss on test and train samples for convoltional network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте и обучите еще одну модель с такой же архитектурой, но используя между каждым Dense слоем и активацией батч нормализацию и слои dropuot после активационных функций.\n",
    "\n",
    "Build and train another model with the samу architecture, using batch-norm layers between every Dense and activational layer, aтв dropout layers afret activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на модель\n",
    "# Have a look at our model (use .summary())\n",
    "\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрисуйте графики точности и потерь на тестовом и на тренировочном множестве для сверточной неронной сети\n",
    "\n",
    "Vusialize the accuracy and the loss on test and train samples for convoltional network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задча №3\n",
    "\n",
    "Реализуйте и обучите полносвязную нейронную сеть с архитектурой 100 -> 200 -> 400 -> 600 -> 800 -> 1000 -> 10. Замерьте время обучения сети. Отрисуйте графики точности и потерь на тестовом и на тренировочном множестве.\n",
    "\n",
    "\n",
    "Build and train fully connected network with architecture 100 -> 200 -> 400 -> 600 -> 800 -> 1000 -> 10, measure learning time. Vusialize the accuracy and the loss on test and train samples for convoltional network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на модель\n",
    "# Have a look at our model (use .summary())\n",
    "\n",
    "\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "Сравнив качество, количество параметров и быстродействии всех трех сетей, сделайте выводы о том, что лучше использовать для работы с изображениями, и какая архитектура должна быть у полносвязных сетей (следующий слой должен содержать больше или меньше нейронов, чем предыдущий?). Подумайте, почему. Сравните результаты обучения полносвязных сетей из задания №2: помогает ли dropuot от переобучения?\n",
    "\n",
    "Compare all charachteristics of all three neworks and make a conclusion, what fully connected architecture if better for iman=ge processing. Why? \n",
    "Compare results from task 2: does dropout help? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовые ноутбуки сохраняйте строго в формате .ipynb, \n",
    "**название файла должно иметь вид: Surname_Name_HWnumber.ipynb . Например: Lindemann_Nikita_03.ipynb\n",
    "\n",
    "## Отправляйте ваши ноутбуки в гугл форму: \n",
    "https://docs.google.com/forms/d/e/1FAIpQLScBQiBqU5Sq2KK1fxy7Ot474vyTUUSG6V63s9tfgKMlbJPecQ/viewform\n",
    "\n",
    "\n",
    "# Спасибо за терпение и выполнение заданий!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
